import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import re
import unicodedata
from rapidfuzz import process, utils
from functools import lru_cache

# ==========================================
# CONFIGURA√á√ÉO E ESTILO
# ==========================================
st.set_page_config(page_title="Dashboard Aqu√°rio Pro+", layout="wide")

st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stMetric {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .stDownloadButton {
        display: flex;
        justify-content: center;
        margin-bottom: 20px;
    }
    </style>
    """, unsafe_allow_html=True)

st.title("üê† Dashboard Gerencial - Aqu√°rio Municipal")
st.markdown("### Processamento Consolidado & Intelig√™ncia Geogr√°fica")

# ==========================================
# LISTA DE REFER√äNCIA (MT + CAPITAIS)
# ==========================================
CIDADES_REFERENCIA = [
    "Cuiab√°", "V√°rzea Grande", "Rondon√≥polis", "Sinop", "Sorriso", "Tangar√° da Serra", 
    "C√°ceres", "Primavera do Leste", "Lucas do Rio Verde", "Barra do Gar√ßas", 
    "Alta Floresta", "Pontes e Lacerda", "Ju√≠na", "Guarant√£ do Norte", "Pocon√©", 
    "Nova Mutum", "Campo Novo do Parecis", "Barra do Bugres", "Colniza", "Vila Rica", 
    "Peixoto de Azevedo", "√Ågua Boa", "Juara", "Col√≠der", "Diamantino", "Canarana", 
    "Campo Verde", "Aripuan√£", "Nova Xavantina", "Sapezal", "Poxor√©u", "Jaciara", 
    "Brasnorte", "Paranatinga", "Pedra Preta", "Guiratinga", "Nova Bandeirantes", 
    "S√£o Jos√© do Rio Claro", "Araputanga", "Matup√°", "Nobres", "Alto Araguaia", 
    "Vila Bela da Sant√≠ssima Trindade", "Campin√°polis", "Juruena", "Porto Alegre do Norte", 
    "Cl√°udia", "Comodoro", "Vera", "Denise", "Ros√°rio Oeste", "Nossa Senhora do Livramento",
    "S√£o Paulo", "Rio de Janeiro", "Bras√≠lia", "Salvador", "Fortaleza", "Belo Horizonte", 
    "Manaus", "Curitiba", "Recife", "Porto Alegre", "Bel√©m", "Goi√¢nia", "Guarulhos", 
    "Campinas", "S√£o Lu√≠s", "Macei√≥", "Duque de Caxias", "Campo Grande", "Natal", 
    "Teresina", "S√£o Bernardo do Campo", "Jo√£o Pessoa", "Osasco", "Santo Andr√©", 
    "Jaboat√£o dos Guararapes", "Uberl√¢ndia", "Contagem", "Sorocaba", "Ribeir√£o Preto", 
    "Aracaju", "Feira de Santana", "Cuiab√°", "Joinville", "Aparecida de Goi√¢nia", 
    "Londrina", "Ananindeua", "Porto Velho", "Serra", "Niter√≥i", "Belford Roxo", 
    "Caxias do Sul", "Campos dos Goytacazes", "Macap√°", "Florian√≥polis", "Boa Vista",
    "Rio Branco", "Vit√≥ria", "Palmas"
]

# ==========================================
# PIPELINE DE SANITIZA√á√ÉO
# ==========================================

@lru_cache(maxsize=1000)
def fuzzy_match_cidade(nome_sujo):
    """Etapa 3: Fuzzy Matching contra lista de refer√™ncia."""
    if not nome_sujo: return ""
    result = process.extractOne(nome_sujo, CIDADES_REFERENCIA, processor=utils.default_process)
    if result and result[1] >= 85:
        return result[0]
    return nome_sujo.title()

def remover_acentos(texto):
    if pd.isna(texto): return ""
    texto = str(texto).lower().strip()
    return ''.join(c for c in unicodedata.normalize('NFKD', texto) 
                  if unicodedata.category(c) != 'Mn')

def sanitizar_pipeline(cidade_origem):
    """Pipeline Triple-Stage Fail-Fast (Expanded LATAM)."""
    if pd.isna(cidade_origem): return "N√£o Informado", False
    
    texto_raw = str(cidade_origem).lower().strip()
    
    # ---------------------------------------------------------
    # STAGE 1: TRADUTOR DE ESTRANGEIROS (Expans√£o LATAM)
    # ---------------------------------------------------------
    mapeamento_estrangeiro = {
        r'\b(usa|eua|united states|texas|florida|miami|new york|orlando)\b': "Estados Unidos",
        r'\b(france|franca|paris)\b': "Fran√ßa",
        r'\b(belgium|belgica|brussels|bruxelas)\b': "B√©lgica",
        r'\b(czech|tcheca|prague)\b': "Rep√∫blica Tcheca",
        r'\b(argentina|buenos aires|cordoba|rosario)\b': "Argentina",
        r'\b(bolivia|la paz|santa cruz|sucre)\b': "Bol√≠via",
        r'\b(paraguay|paraguai|asuncion|assuncao)\b': "Paraguai",
        r'\b(chile|santiago|valparaiso)\b': "Chile",
        r'\b(uruguay|uruguai|montevideo|punta del este)\b': "Uruguai",
        r'\b(colombia|bogota|medellin|cartagena)\b': "Col√¥mbia",
        r'\b(peru|lima|cusco|machu picchu)\b': "Peru",
        r'\b(venezuela|caracas|maracaibo)\b': "Venezuela",
        r'\b(ecuador|equador|quito|guayaquil)\b': "Equador",
        r'\b(mexico|cancun|mexico city)\b': "M√©xico",
        r'\b(portugal|lisboa|porto)\b': "Portugal",
        r'\b(spain|espanha|madrid|barcelona)\b': "Espanha",
        r'\b(italy|italia|rome|roma|milano)\b': "It√°lia",
        r'\b(germany|alemanha|berlin|munich)\b': "Alemanha",
        r'\b(japan|japao|tokyo|toquio)\b': "Jap√£o",
        r'\b(china|beijing|shanghai)\b': "China",
        r'\b(uk|reino unido|london|londres|england|inglaterra)\b': "Reino Unido"
    }
    
    for regex, pais in mapeamento_estrangeiro.items():
        if re.search(regex, texto_raw):
            return pais, True
            
    # ---------------------------------------------------------
    # STAGE 2: SIGLAS E LIMPEZA LOCAL
    # ---------------------------------------------------------
    c_limpa = remover_acentos(texto_raw)
    c_limpa = re.sub(r'(\bmt\b|\bbr\b|\bbrasil\b|[-/])', ' ', c_limpa).strip()
    c_limpa = re.sub(r'\s+', ' ', c_limpa)
    
    siglas = {
        r'\bcba\b': "Cuiab√°",
        r'\bvg\b': "V√°rzea Grande",
        r'\bsp\b': "S√£o Paulo",
        r'\bbh\b': "Belo Horizonte",
        r'\brj\b': "Rio de Janeiro",
        r'\bcgr\b': "Campo Grande",
        r'\bcur\b': "Curitiba",
        r'\bgyn\b': "Goi√¢nia"
    }
    
    for sigla_re, nome_oficial in siglas.items():
        if re.search(sigla_re, c_limpa):
            return nome_oficial, False

    # ---------------------------------------------------------
    # STAGE 3: FUZZY MATCHING
    # ---------------------------------------------------------
    nome_final = fuzzy_match_cidade(c_limpa)
    return nome_final, False

# ==========================================
# UPLOAD E CARREGAMENTO
# ==========================================
uploaded_files = st.file_uploader(
    "Upload de arquivos de visitantes (XLSX ou CSV)", 
    type=['xlsx', 'csv'], 
    accept_multiple_files=True
)

if uploaded_files:
    dataframes = []
    
    for f in uploaded_files:
        try:
            if f.name.endswith('.csv'):
                try: df_cur = pd.read_csv(f)
                except: df_cur = pd.read_csv(f, encoding='latin1', sep=';')
            else:
                df_cur = pd.read_excel(f)
            
            if df_cur.shape[1] >= 6:
                df_cur = df_cur.iloc[:, 0:7]
                df_cur.columns = ['Data_Hora', 'Nome', 'Cidade_Origem', 'Whatsapp', 'Idade', 'Qtd_Criancas', 'Obs']
                dataframes.append(df_cur)
        except Exception as e:
            st.error(f"Erro no arquivo {f.name}: {e}")

    if not dataframes:
        st.stop()

    df_raw = pd.concat(dataframes, ignore_index=True)

    try:
        # ==========================================
        # PIPELINE DE TRATAMENTO
        # ==========================================
        
        # 1. Datas
        df_raw['Data_Hora'] = pd.to_datetime(df_raw['Data_Hora'], errors='coerce')
        df = df_raw.dropna(subset=['Data_Hora']).copy()
        df['Data'] = df['Data_Hora'].dt.date
        mapa_dias = {'Monday': 'Segunda', 'Tuesday': 'Ter√ßa', 'Wednesday': 'Quarta', 'Thursday': 'Quinta', 'Friday': 'Sexta', 'Saturday': 'S√°bado', 'Sunday': 'Domingo'}
        df['Dia_Semana'] = df['Data_Hora'].dt.strftime('%A').map(mapa_dias)
        df['Dia_Semana'] = pd.Categorical(df['Dia_Semana'], categories=list(mapa_dias.values()), ordered=True)

        # 2. Sanitiza√ß√£o Num√©rica
        def process_criancas(val):
            if pd.isna(val): return 0
            s = str(val).lower().strip()
            if any(term in s for term in ["nenhum", "nenhuma", "n√£o", "nao", "zero"]): return 0
            match = re.search(r'(\d+)', s)
            return int(match.group(1)) if match else 0

        df['Qtd_Criancas'] = df['Qtd_Criancas'].apply(process_criancas)
        
        lim_exc = 40
        med_cr = df[df['Qtd_Criancas'] <= lim_exc]['Qtd_Criancas'].mean()
        df.loc[df['Qtd_Criancas'] > lim_exc, 'Qtd_Criancas'] = int(round(med_cr)) if not np.isnan(med_cr) else 0

        def process_idade(val):
            if pd.isna(val): return np.nan
            match = re.search(r'(\d+)', str(val))
            if match:
                idade = int(match.group(1))
                return idade if 1 <= idade <= 120 else np.nan
            return np.nan

        df['Idade'] = df['Idade'].apply(process_idade)

        # 3. Sanitiza√ß√£o 3-Stage
        with st.spinner("Aplicando Intelig√™ncia Geogr√°fica..."):
            resultados = df['Cidade_Origem'].apply(sanitizar_pipeline)
            df['Cidade_Limpa'] = [r[0] for r in resultados]
            df['Estrangeiro'] = [r[1] for r in resultados]

        df['Total_Visitantes_Linha'] = 1 + df['Qtd_Criancas']
        df['Tipo_Grupo'] = df['Qtd_Criancas'].apply(lambda x: 'Fam√≠lia/Grupo' if x > 0 else 'Individual/Adultos')

        # ==========================================
        # INTERFACE E FILTROS
        # ==========================================
        st.sidebar.header("üîç Filtros Avan√ßados")
        periodo = st.sidebar.date_input("Intervalo de Datas", [df['Data'].min(), df['Data'].max()])
        gringos_only = st.sidebar.toggle("Focar Apenas em Estrangeiros")

        df_f = df.copy()
        if len(periodo) == 2:
            df_f = df_f[(df_f['Data'] >= periodo[0]) & (df_f['Data'] <= periodo[1])]
        if gringos_only:
            df_f = df_f[df_f['Estrangeiro']]

        if df_f.empty:
            st.warning("Sem dados para os filtros selecionados.")
        else:
            # KPIs
            t_ge = int(df_f['Total_Visitantes_Linha'].sum())
            t_ad = len(df_f)
            t_cr = int(df_f['Qtd_Criancas'].sum())
            t_est = int(df_f[df_f['Estrangeiro']]['Total_Visitantes_Linha'].sum())

            c1, c2, c3, c4 = st.columns(4)
            c1.metric("P√∫blico Total", f"{t_ge:,}".replace(',','.'))
            c2.metric("Adultos", f"{t_ad:,}".replace(',','.'))
            c3.metric("Crian√ßas", f"{t_cr:,}".replace(',','.'))
            c4.metric("Estrangeiros", f"{t_est:,}".replace(',','.'))
            
            st.markdown("---")
            
            # BOT√ÉO DE EXPORTA√á√ÉO (FILTRADO)
            csv = df_f.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Baixar Planilha Higienizada (CSV)",
                data=csv,
                file_name='visitantes_higienizados.csv',
                mime='text/csv',
            )

            # Gr√°ficos (Matplotlib/Seaborn)
            sns.set_theme(style="whitegrid")
            fig = plt.figure(figsize=(22, 14))
            plt.subplots_adjust(hspace=0.4, wspace=0.3)
            plt.suptitle('Dashboard Aqu√°rio - An√°lise Inteligente', fontsize=18, fontweight='bold', y=0.98)

            # 1. Composi√ß√£o
            plt.subplot(2, 3, 1)
            plt.pie([t_ad, t_cr], labels=['Adultos', 'Crian√ßas'], autopct='%1.1f%%', colors=['#3498db', '#f1c40f'], startangle=90, explode=(0.05, 0))
            plt.title('Distribui√ß√£o Adultos vs Crian√ßas', fontweight='bold')

            # 2. Perfil
            plt.subplot(2, 3, 2)
            df_f['Tipo_Grupo'].value_counts().plot.pie(autopct='%1.1f%%', colors=['#e74c3c', '#2ecc71'], startangle=90)
            plt.title('Perfil dos Visitantes', fontweight='bold')
            plt.ylabel('')

            # 3. Evolu√ß√£o
            plt.subplot(2, 3, 3)
            df_f.groupby('Data')['Total_Visitantes_Linha'].sum().plot(marker='o', color='#8e44ad')
            plt.title('Fluxo de Visitantes no Per√≠odo', fontweight='bold')
            plt.xticks(rotation=45)

            # 4. M√©dias
            plt.subplot(2, 3, 4)
            media_op = df_f.groupby('Dia_Semana')['Total_Visitantes_Linha'].sum() / df_f.groupby('Dia_Semana')['Data'].nunique()
            sns.barplot(x=media_op.index, y=media_op.values, palette="rocket")
            plt.title('M√©dia de Visitantes por Dia', fontweight='bold')

            # 5. Top Cidades
            plt.subplot(2, 3, 5)
            top_10 = df_f['Cidade_Limpa'].value_counts().head(10)
            sns.barplot(x=top_10.values, y=top_10.index, palette="viridis")
            plt.title('Top 10 Cidades de Origem', fontweight='bold')

            # 6. Estrangeiros
            plt.subplot(2, 3, 6)
            if t_est > 0:
                top_es = df_f[df_f['Estrangeiro']]['Cidade_Limpa'].value_counts().head(5)
                sns.barplot(x=top_es.values, y=top_es.index, palette="copper")
                plt.title('Top Pa√≠ses Estrangeiros', fontweight='bold')
            else:
                plt.text(0.5, 0.5, "Sem Estrangeiros no Per√≠odo", ha='center', va='center', color='gray')
                plt.axis('off')

            st.pyplot(fig)

    except Exception as e:
        st.error(f"üö® Erro no processamento: {e}")
else:
    st.info("üí° Carregue os arquivos para consolidar a an√°lise e liberar a exporta√ß√£o.")
